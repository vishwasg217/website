{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":""},{"location":"#hi-im-vishwas-gowda","title":"Hi \ud83d\udc4b, I'm Vishwas Gowda","text":"<p>I am a passionate AI/ML Engineer. I love working on ML and NLP problems, and I'm currently building LLM-based solutions in finance at Pipe Technologies</p>"},{"location":"#projects","title":"Projects","text":"<p>Here are some of the projects I have worked on:</p> <ul> <li> <p>FinSight: Financial Insights At Your Fingertips</p> </li> <li> <p>ML From Scratch: Core Machine Algos Implemented From Scratch</p> </li> <li> <p>AI Email Campaign Generator</p> </li> </ul>"},{"location":"#blogs","title":"Blogs","text":"<p>How I built the Streamlit LLM Hackathon winning app \u2014 FinSight using LlamaIndex.: A technical dive into building the FinSight app using LlamaIndex.</p> <p>Understanding and Building ReAct Agents: A detailed guide on ReAct agents and building it from scratch.</p> <p>Comprehensive Guide on TF-IDF: A detailed blog on TF-IDF and its workings under the hood.</p> <p>BM25 Explained: A Better Ranking Algorithm than TF-IDF: A technical deepdive on BM25 and how it is better than TF-IDF.</p>"},{"location":"blog/2025/01/20/bm25-explained-a-better-ranking-algorithm-than-tf-idf/","title":"BM25 Explained: A Better Ranking Algorithm than TF-IDF","text":"<p>BM25 algorithm is a popular ranking function used in information retrieval tasks such as search engines. However, BM25 search has also become increasingly popular for RAG (Retrieval Augmented Generation) based systems for ranking documents based on their relevance to a query.</p> <p>BM25 search is an improved version of the TF-IDF algorithm that addresses some of its limitations. In this article, we will explore the BM25 algorithm in detail, understand its components, compare it with TF-IDF, and implement it from scratch. But before diving into BM25, it is essential to understand the nitigrities of TF-IDF, which you can find in my previous article.</p>","tags":["NLP","Information Retrieval","RAG"]},{"location":"blog/2025/01/20/bm25-explained-a-better-ranking-algorithm-than-tf-idf/#understanding-bm25","title":"Understanding BM25","text":"<p>As previously mentioned, BM25 is an improved version of the TF-IDF algorithm that addresses some of its limitations. BM25 stands for Best Matching 25. So naturally the formula for BM25 is a bit similar to TF-IDF but with some modifications. This formula also contains the term frequency (TF) and inverse document frequency (IDF) components, but it introduces additional parameters to control the term frequency saturation and document length normalization.</p>","tags":["NLP","Information Retrieval","RAG"]},{"location":"blog/2025/01/20/bm25-explained-a-better-ranking-algorithm-than-tf-idf/#bm25-formula","title":"BM25 Formula","text":"\\[ \\text{BM25}(d, q) = \\sum_{t \\in q} \\text{IDF}(t) \\cdot \\frac{f_{t, d} \\cdot (k_1 + 1)}{f_{t, d} + k_1 \\cdot (1 - b + b \\cdot \\frac{|d|}{\\text{avgdl}})} \\]","tags":["NLP","Information Retrieval","RAG"]},{"location":"blog/2025/01/20/bm25-explained-a-better-ranking-algorithm-than-tf-idf/#where","title":"Where","text":"<ol> <li>\\(t\\): A term in the query.</li> <li>\\(f_{t, d}\\): The frequency of term \\(t\\) in document \\(d\\) (term frequency).</li> <li>\\(|d|\\): The length of document \\(d\\) (number of terms in \\(d\\)).</li> <li>\\(\\text{avgdl}\\): The average document length in the corpus.</li> <li>\\(\\text{IDF}(t)\\): The inverse document frequency of term \\(t\\), calculated as:    $$    \\text{IDF}(t) = \\log\\left(\\frac{N - n_t + 0.5}{n_t + 0.5} + 1\\right)    $$</li> <li>\\(N\\): Total number of documents.</li> <li>\\(n_t\\): Number of documents containing term \\(t\\).</li> <li>\\(k_1\\): Controls the term frequency saturation (commonly set to 1.2).</li> <li>\\(b\\): Controls the document length normalization (commonly set to 0.75).</li> </ol>","tags":["NLP","Information Retrieval","RAG"]},{"location":"blog/2025/01/20/bm25-explained-a-better-ranking-algorithm-than-tf-idf/#why-bm25-is-better-than-tf-idf","title":"Why BM25 is better than tf-idf?","text":"","tags":["NLP","Information Retrieval","RAG"]},{"location":"blog/2025/01/20/bm25-explained-a-better-ranking-algorithm-than-tf-idf/#limitations-of-tf-idf","title":"Limitations of TF-IDF","text":"<p>While TF-IDF is a good measure for information retrieval, it has some limitations.</p> <p>1. Lack of Saturation for Term Frequency: TF-IDF does not have a saturation point for term frequency. This means that the score for a document keeps increasing linearly with the increase in the frequency of a term in the document. For example, a document that has the term <code>apple</code> 15 times may not be much more relevant than a document that has the term <code>apple</code> 5 times. However, the difference in the score between these two documents will be significant in TF-IDF.</p> <p>2. Bias for longer documents: TF-IDF has a bias towards longer documents. This is because longer documents tend to have more terms and hence a higher term frequency. This can lead to longer documents being ranked higher than shorter documents even if the shorter documents are more relevant.</p> <p>3. Unbounded values for IDF: Rarer terms have a higher IDF value, which can lead to unbounded scores for these terms. This can skew the ranking of documents towards rare terms, which may not be the most relevant document to the query.</p>","tags":["NLP","Information Retrieval","RAG"]},{"location":"blog/2025/01/20/bm25-explained-a-better-ranking-algorithm-than-tf-idf/#how-bm25-addresses-these-limitations","title":"How BM25 Addresses These Limitations","text":"<p>1. Adding Saturation for Term Frequency: BM25 introduces a saturation point for term frequency by using the term frequency saturation parameter \\(k_1\\). This parameter controls how quickly the score increases with the increase in term frequency. By setting an appropriate value for \\(k_1\\), we can ensure that the score does not increase linearly with term frequency and reaches a saturation point.</p> <p>Example:</p> <p>Imagine two documents about fruits: Document 1: Mentions \"apple\" 3 times. Document 2: Mentions \"apple\" 15 times.</p> <p>With \\(k_1 = 1.5\\):</p> <ul> <li>For Document 1:   $$   \\text{TF factor} = \\frac{3}{3 + 1.5} = \\frac{3}{4.5} \\approx 0.67   $$</li> <li>For Document 2:   $$   \\text{TF factor} = \\frac{15}{15 + 1.5} = \\frac{15}{16.5} \\approx 0.91   $$</li> </ul> <p>Notice that the jump from 3 to 15 repetitions increases the score, but not proportionally.</p> <p>With \\(k_1 = 0.5\\):</p> <ul> <li>For Document 1:   $$   \\text{TF factor} = \\frac{3}{3 + 0.5} = \\frac{3}{3.5} \\approx 0.86   $$</li> <li>For Document 2:   $$   \\text{TF factor} = \\frac{15}{15 + 0.5} = \\frac{15}{15.5} \\approx 0.97   $$</li> </ul> <p>With a smaller \\(k_1\\), the effect of term frequency is further reduced, and the scores for the two documents become closer.</p> <p>2. Length Normalization: BM25 introduces a length normalization parameter \\(b\\) that helps to address the bias towards longer documents.  It adjusts the importance of term frequency normalization based on the length of a document compared to the average document length. Here's how it works:</p> <ul> <li> <p>\\(b = 0\\): No length normalization is applied. Long and short documents are treated equally in terms of their length.</p> </li> <li> <p>\\(b = 1\\): Full length normalization is applied. Term frequency is scaled entirely by the document's length relative to the average length.</p> </li> <li> <p>Intermediate values (e.g., \\(b = 0.75\\)): Partial length normalization is applied (this is the typical default). It balances the influence of document length on the score, ensuring long documents aren't overly penalized and short ones aren't overly favored.</p> </li> </ul> <p>3. Adding Smoothing Constants: BM25 introduces smoothing constants (+0.5) to prevent extreme values for rare terms and balances the weights between rare and frequent terms. As a result, BM25 avoids overemphasizing rare terms while still highlighting their importance in a more controlled way. This creates a more balanced and practical scoring mechanism for ranking documents.</p> <p>Practical Example:</p> <p>Dataset:</p> <ul> <li>\\(N = 100\\) documents</li> <li>\\(n_t = 50\\) (term appears in half the documents)</li> </ul> <p>IDF Comparison:</p> <ul> <li> <p>TF-IDF:   $$   \\text{IDF} = \\log\\left(\\frac{100}{50}\\right) = \\log(2) \\approx 0.693   $$</p> </li> <li> <p>BM25:   $$   \\text{IDF} = \\log\\left(\\frac{100 - 50 + 0.5}{50 + 0.5} + 1\\right) = \\log\\left(\\frac{50.5}{50.5} + 1\\right) = \\log(2) \\approx 0.693   $$</p> </li> </ul> <p>Here, both are similar because \\(n_t\\) is moderate.</p> <p>For Rare Term (\\(n_t = 1\\)):</p> <ul> <li> <p>TF-IDF:   $$   \\text{IDF} = \\log\\left(\\frac{100}{1}\\right) = \\log(100) \\approx 4.605   $$</p> </li> <li> <p>BM25:   $$   \\text{IDF} = \\log\\left(\\frac{100 - 1 + 0.5}{1 + 0.5} + 1\\right) = \\log\\left(\\frac{99.5}{1.5} + 1\\right) = \\log(67.33) \\approx 4.208   $$</p> </li> </ul> <p>BM25 gives a slightly lower score, smoothing the impact of very rare terms.</p> <ul> <li>TF-IDF IDF: Simple but can overemphasize rare terms and lacks robustness.</li> <li>BM25 IDF: Smoothed and balanced, making it more suitable for real-world search and ranking tasks.</li> </ul> <p>BM25's IDF is tailored for document ranking, where the balance between common and rare terms is crucial for relevance.</p>","tags":["NLP","Information Retrieval","RAG"]},{"location":"blog/2025/01/20/bm25-explained-a-better-ranking-algorithm-than-tf-idf/#code-implementation-of-bm25","title":"Code implementation of BM25","text":"","tags":["NLP","Information Retrieval","RAG"]},{"location":"blog/2025/01/20/bm25-explained-a-better-ranking-algorithm-than-tf-idf/#simple-implemenation-using-library","title":"Simple implemenation using library","text":"<p>Before we implement BM25 from scratch, let's see how we can use the <code>rank_bm25</code> library to calculate BM25 scores for a query and retrieve the top documents based on these scores.</p> <pre><code>from rank_bm25 import BM25Okapi\n\ncorpus = [\n    \"Apple Apple Banana\",\n    \"Banana Mango Banana\",\n    \"Cherry Cherry Strawberries\",\n    \"Grapes Grapes Strawberries Grapes\",\n    \"Apple Banana Mango\",\n    \"Blueberries Strawberries Apple\",\n    \"Apple Banana Mango\",\n    \"Grapes Grapes Grapes\",\n    \"Blueberries Apple Strawberries\",\n    \"Apple Banana Apple\",\n    \"Cherry Cherry Mango Cherry\",\n    \"Blueberries Strawberries Cherry\",\n]\ntokenized_corpus = [doc.lower().split(\" \") for doc in corpus]\nbm25 = BM25Okapi(tokenized_corpus)\n\nquery = \"banana mango\"\ntokenized_query = query.lower().split(\" \")\n\ndoc_scores = bm25.get_scores(tokenized_query)\nprint(doc_scores)\n\ndocs = bm25.get_top_n(tokenized_query, tokenized_corpus, n=5)\ndocs\n</code></pre> <p><code>BM25Okapi</code> is a class that implements the BM25 algorithm. It takes a tokenized corpus as input and provides methods to calculate scores for queries and retrieve the top documents based on these scores. The <code>get_scores</code> method calculates the BM25 score for each document in the corpus based on the query, while the <code>get_top_n</code> method retrieves the top <code>n</code> documents based on these scores.</p> <p>Output:</p> <pre><code>[0.3176789  1.10212021 0.         0.         0.96909597 0.\n 0.96909597 0.         0.         0.3176789  0.56864878 0.        ]\n[['banana', 'mango', 'banana'],\n ['apple', 'banana', 'mango'],\n ['apple', 'banana', 'mango'],\n ['cherry', 'cherry', 'mango', 'cherry'],\n ['apple', 'banana', 'apple']]\n</code></pre>","tags":["NLP","Information Retrieval","RAG"]},{"location":"blog/2025/01/20/bm25-explained-a-better-ranking-algorithm-than-tf-idf/#from-scratch-implementation","title":"From scratch implementation","text":"","tags":["NLP","Information Retrieval","RAG"]},{"location":"blog/2025/01/20/bm25-explained-a-better-ranking-algorithm-than-tf-idf/#from-scratch-module","title":"from scratch module","text":"<pre><code>import math\nimport numpy as np\nfrom collections import Counter\n\nclass BM25:\n    def __init__(self, corpus: list[str], k1: float = 1.2, b: float = 0.75):\n        tokenized_corpus = [doc.lower().split(\" \") for doc in corpus]\n        self.k1 = k1\n        self.b = b\n        self.N = len(tokenized_corpus)\n        self.doc_len = []\n        self.avg_dl = None\n        self.nd, self.document_frequencies = self.initialize(tokenized_corpus)\n        self.idf = self.calculate_idf(self.nd)\n\n    def initialize(self, corpus):\n        nd = {}\n        document_frequencies = []\n        total_doc_len = 0\n        for doc in corpus:\n            doc_len = len(doc)\n            self.doc_len.append(doc_len)\n            total_doc_len += doc_len\n            document_frequencies.append(dict(Counter(doc)))\n            for term in set(doc):\n                if term not in nd:\n                    nd[term] = 1\n                else: \n                    nd[term] += 1\n\n        self.avg_dl = total_doc_len / self.N\n        return nd, document_frequencies\n\n    def calculate_idf(self, nd):\n        idf = {}\n        for term in nd:\n            idf[term] = math.log((self.N - nd[term] + 0.5) / (nd[term] + 0.5) + 1)\n\n        return idf\n\n    def get_scores(self, query: str):\n        query = query.lower().split(\" \")\n        scores = np.zeros(self.N)\n        for q in query:\n            idf_q = self.idf[q]\n            # this is a list of f_q since we are calculating the score for each document \n            f_q = np.array([doc.get(q, 0)  for doc in self.document_frequencies])\n            scores += idf_q * (f_q * (self.k1 + 1)) / (f_q + (self.k1 * (1 - self.b + (self.b * np.array(self.doc_len) / self.avg_dl))))\n\n        return scores\n\n    def get_top_n(self, query: str, documents: list[str], top_n: int = 5):\n        if len(documents) != self.N:\n            raise ValueError(\"The documents do not match the indexed corpus\")\n\n        scores = self.get_scores(query)\n        top_n = np.argsort(scores)[::-1][:5]\n        return [{\"doc_id\": int(i), \"doc\": documents[i], \"score\": round(float(scores[i]), 3)} for i in top_n]\n</code></pre> <p>The <code>BM25</code> class implements the BM25 algorithm from scratch. This class has 3 main methods:</p> <ol> <li><code>__init__()</code>: Initializes the BM25 model with the corpus and sets the parameters \\(k_1\\) and \\(b\\).</li> <li><code>initialize()</code>: This method calculates the <code>nd</code> and <code>document_frequencies</code>. <code>nd</code> is a dictionary that stores the number of documents containing each term, while <code>document_frequencies</code> is a list of dictionaries that store the term frequencies for each document. It also calculates the average document length <code>avg_dl</code>.</li> <li><code>calculate_idf()</code>: This method calculates the IDF values for each term in the corpus based on the formula provided earlier.</li> <li><code>get_scores()</code>: This method calculates the BM25 scores for each document in the corpus based on the query. It returns an array of scores for each document. While iterating over the query terms:<ul> <li>It gets the IDF value for the term.</li> <li>It calculates the term frequency (f_{t, d}$ in the formula) for the term in each document.</li> <li>It calculates the BM25 score (as per the above formula) for the term in each document and adds it to the total score.</li> </ul> </li> <li><code>get_top_n()</code>: This method retrieves the top <code>n</code> documents based on the BM25 scores. It returns a list of dictionaries containing the document ID, the document text, and the BM25 score for each of the top documents.</li> </ol>","tags":["NLP","Information Retrieval","RAG"]},{"location":"blog/2025/01/20/bm25-explained-a-better-ranking-algorithm-than-tf-idf/#use-module","title":"use module","text":"<pre><code>bm25 = BM25(corpus)\nprint(f\"Term Count: {bm25.nd}\")\nprint(f\"Avg Doc Length: {bm25.avg_dl}\")\nprint(f\"Document Frequencies: {bm25.document_frequencies}\")\n</code></pre> <p>Output:</p> <pre><code>Term Count: {'apple': 6, 'banana': 5, 'mango': 4, 'strawberries': 5, 'cherry': 3, 'grapes': 2, 'blueberries': 3}\nAvg Doc Length: 3.1666666666666665\nDocument Frequencies: [{'apple': 2, 'banana': 1}, {'banana': 2, 'mango': 1}, {'cherry': 2, 'strawberries': 1}, {'grapes': 3, 'strawberries': 1}, {'apple': 1, 'banana': 1, 'mango': 1}, {'blueberries': 1, 'strawberries': 1, 'apple': 1}, {'apple': 1, 'banana': 1, 'mango': 1}, {'grapes': 3}, {'blueberries': 1, 'apple': 1, 'strawberries': 1}, {'apple': 2, 'banana': 1}, {'cherry': 3, 'mango': 1}, {'blueberries': 1, 'strawberries': 1, 'cherry': 1}]\n</code></pre> <pre><code>queries = [\n    \"apple mango\",\n    \"grapes\",\n    \"banana mango\",\n    \"Cherry\",\n    \"apple\",\n    \"Blueberries Strawberries\"\n]\n\nquery = queries[2]\n\nprint(f\"Query: {query}\")\nscores = bm25.get_scores(query)\nprint(f\"Scores: {scores}\")\ndocs = bm25.get_top_n(query, corpus)\ndocs\n</code></pre> <p>Output:</p> <pre><code>Query: banana mango\nScores: [0.8791299  2.28476434 0.         0.         1.96334623 0.\n 1.96334623 0.         0.         0.8791299  0.95776345 0.        ]\n[{'doc_id': 1, 'doc': 'Banana Mango Banana', 'score': 2.285},\n {'doc_id': 6, 'doc': 'Apple Banana Mango', 'score': 1.963},\n {'doc_id': 4, 'doc': 'Apple Banana Mango', 'score': 1.963},\n {'doc_id': 10, 'doc': 'Cherry Cherry Mango Cherry', 'score': 0.958},\n {'doc_id': 9, 'doc': 'Apple Banana Apple', 'score': 0.879}]\n</code></pre>","tags":["NLP","Information Retrieval","RAG"]},{"location":"blog/2025/01/20/bm25-explained-a-better-ranking-algorithm-than-tf-idf/#conclusion","title":"Conclusion","text":"<p>BM25 is a powerful ranking algorithm that addresses some of the limitations of TF-IDF by introducing term frequency saturation, document length normalization, and smoothing constants. By balancing the importance of term frequency and document length, BM25 provides more robust and relevant document rankings for information retrieval tasks.</p>","tags":["NLP","Information Retrieval","RAG"]},{"location":"blog/2024/12/20/understanding-and-building-react-agents/","title":"Understanding and Building ReAct Agents","text":"<p>In this blog, we will understand what ReAct agents are, why they are required, the pros and cons of using them and also dive into how they work under the hood. We will also build a simple ReAct agent from scratch that can solve problems using external tools.</p>","tags":["AI","LLMs","Agents"]},{"location":"blog/2024/12/20/understanding-and-building-react-agents/#what-is-a-react-agent","title":"What is a ReAct Agent?","text":"<p>A ReAct (Reasoning and Act) Agent is an autonomous agent architecture that uses reasoning and action planning capabilities of LLMs for general task solving. Given a task and the tools to solve it, a ReAct agent dynamically plans and executes a sequence of actions to solve the task.</p>","tags":["AI","LLMs","Agents"]},{"location":"blog/2024/12/20/understanding-and-building-react-agents/#why-is-it-required","title":"Why is it required?","text":"","tags":["AI","LLMs","Agents"]},{"location":"blog/2024/12/20/understanding-and-building-react-agents/#limitations-of-chain-of-thought-prompting","title":"Limitations of Chain of Thought Prompting","text":"<p>CoT (Chain of Thought) prompting is not good enough for dynamic problem solving for the following reasons:</p> <ol> <li>CoT follows a fixed sequence and cannot dynamically adapt based on the current state of the task.</li> <li>CoT prompting typically does not have any access to external tools.</li> <li>It does not perform well over long sequences of reasoning as hallucinations are more prevalent in CoT since the model is not groudned in truth.</li> </ol>","tags":["AI","LLMs","Agents"]},{"location":"blog/2024/12/20/understanding-and-building-react-agents/#limitation-of-act-only-agents","title":"Limitation of Act-Only Agents","text":"<p>Act-only agents are not explainable. They are black-boxes that take in an input and produce an output. There is no way to understand why a particular action was taken. This is can be limiting especially when the agent prompt needs to be \"debugged\" and improved.</p>","tags":["AI","LLMs","Agents"]},{"location":"blog/2024/12/20/understanding-and-building-react-agents/#how-react-agents-solve-these-limitations","title":"How ReAct Agents Solve These Limitations","text":"<ol> <li>Dynamic Planning: ReAct agents can dynamically plan and execute a sequence of actions to solve a task based on the previous results.</li> <li>Accurate Information: ReAct Agents integrate external tools such as APIs, databases, calculators, etc. to solve tasks. This makes sure that they have access to latest information and more accurate results to work with.</li> <li>Explainability: sequences of ReAct agents contains a reasoning/thought step which can be used to understand why a particular action was taken.</li> <li>Reliability: With each sequence contain a reasoning, action, and observation step the agent is more grounded and trustworthy, since the each sequence is more structured and constrained.</li> </ol>","tags":["AI","LLMs","Agents"]},{"location":"blog/2024/12/20/understanding-and-building-react-agents/#pros-and-cons-of-react-agents","title":"Pros and Cons of ReAct Agents","text":"","tags":["AI","LLMs","Agents"]},{"location":"blog/2024/12/20/understanding-and-building-react-agents/#pros","title":"Pros","text":"<ol> <li>Enhanced Problem Solving Abilities: Since ReAct agents can use external tools and also dynamically adapt, they can create a wide range of sophisticated and lengthy workflows to solve a probelm reliably.</li> <li>Versatility: ReAct Agents can handle a variety of tasks as long as they have necessary tools to access information that aid them.</li> <li>Access to new Information: ReAct agents can access external tools and APIs to get the latest information to solve a task. Whereas CoT and other methods are limited to the information the model was trained on or is present in the prompt.</li> </ol>","tags":["AI","LLMs","Agents"]},{"location":"blog/2024/12/20/understanding-and-building-react-agents/#cons","title":"Cons","text":"<ol> <li> <p>Requires Large Models: For ReAct agents to work decently, larger language models such as GPT-3 or GPT-4 will have to be used.This means if the LLM being used is an open source model, then the computational overhead will be high, and if it is a closed source model, then the API costs will be higher.</p> </li> <li> <p>High Latency: ReAct agents require large models and also takes multiple sequences to solve a task. This means that the latency of the agent will be high. This can be a problem for real-time applications.</p> </li> <li> <p>Simple ReAct agents setups may not be enough: The ReAct agent prompt setup, workflow and the tools need to be carefully designed to make sure that the agent is able to solve the task. Especially when the task is highly domain specific or requires a lot of external information. A simple plug-and-play setup using LangChain/LlamaIndex may not be enough.</p> </li> </ol>","tags":["AI","LLMs","Agents"]},{"location":"blog/2024/12/20/understanding-and-building-react-agents/#understanding-the-react-agent-framework","title":"Understanding the ReAct Agent Framework","text":"<p>The ReAct Agent Framework Diagram above shows the different components and the sequence in which they are used:</p> <ul> <li>User Query: The user query is the task that the ReAct agent needs to solve.</li> <li>LLM: The large language model is used to generate the reasoning and action steps.</li> <li>Tools: The tools are the external APIs, databases, calculators, etc. that the ReAct agent has access to solve the task.</li> <li>Traces: This is a list of steps takes by the React Agent to solve the task. Each step contains the following:<ol> <li>Thought: The LLM's reasoning about the query why a particular action was taken.</li> <li>Action: The action that the ReAct agent takes to solve the task.</li> <li>Observation: The output of the tool that the ReAct agent used to solve the task. Along with the Tools Desceiptions, the Traces are sent to the LLM to generate the next step in the sequence. This new step is added back to the Traces and the process is repeated until a final satisfactory answer is obtained.</li> </ol> </li> <li>Tools Description: This contains a description of each of the tools that is available to the ReAct agent. This can be APIs, databases, calculators, etc.</li> <li>Tool Call and Tool Response: The Tool Call is a specific query that contains the tool name and its parameters. The Tool Response is the output of that tool, which becomes the observation in the trace.</li> <li>Result: Once the LLM decides that a satisfactory result that answers the user's query has been obtained, the result is returned to the user. The LLM decides that result has been obtained based on the traces provided.</li> </ul>","tags":["AI","LLMs","Agents"]},{"location":"blog/2024/12/20/understanding-and-building-react-agents/#building-a-react-agent-from-scratch","title":"Building a ReAct Agent from Scratch","text":"","tags":["AI","LLMs","Agents"]},{"location":"blog/2024/12/20/understanding-and-building-react-agents/#tools-implementation","title":"Tools Implementation","text":"<p>In this example, we will provide the ReAct agent with simple tools that that can calculate properties such as area, perimeter, and diagonal of certain shapes. The tools that we will provide are:</p> <ol> <li><code>determine_formula</code>: This tool will determine the correct formula to be used based on the user query.</li> <li><code>calculate</code>: This tool will provide the accurate calculation for given expression.</li> </ol> <p>While the latest models are decent at doing the tasks of the above tools, it is still better to use external tools for more reliable results.</p> <pre><code>import math\n\ndef determine_formula(shape: str, property: str):\n    formulae = {\n        \"rectangle\": {\n            \"area\": \"length * breadth\",\n            \"perimeter\": \"2 * (length + breadth)\",\n            \"diagonal\": \"sqrt(length ** 2 + breadth ** 2)\"\n        },\n        \"square\": {\n            \"area\": \"side ** 2\",\n            \"perimeter\": \"4 * side\",\n            \"diagonal\": \"sqrt(2) * side\"\n        },\n        \"circle\": {\n            \"area\": \"pi * radius ** 2\",\n            \"perimeter\": \"2 * pi * radius\",\n            \"diameter\": \"2 * radius\",\n            \"circumference\": \"2 * pi * radius\"\n        },\n        \"triangle\": {\n            \"area\": \"0.5 * base * height\",\n            \"perimeter\": \"side1 + side2 + side3\",\n            \"diagonal\": \"sqrt(side1 ** 2 + side2 ** 2)\"\n        },\n        \"parallelogram\": {\n            \"area\": \"base * height\",\n            \"perimeter\": \"2 * (side1 + side2)\",\n            \"diagonal\": \"sqrt(side1 ** 2 + side2 ** 2 + 2 * side1 * side2 * cos(angle))\"\n        },\n    }\n\n    if shape in formulae:\n        if property in formulae[shape]:\n            return formulae[shape][property]\n        else:\n            return \"Invalid formula\"\n\n    else:\n        return \"Invalid shape\"\n\ndef calculate_expression(expression: str):\n    return eval(expression, {\"__builtins__\": None}, {\"sqrt\": math.sqrt, \"pi\": math.pi, \"cos\": math.cos})\n\n\ntools_description = {\n    \"determine_properties\": {\n        \"description\": \"Always use this tool to determine the formula required.\",\n        \"input_params\": {\n            \"shape\": \"The shape for which the formula is to be determined\",\n            \"property\": \"The property for which the formula needs to determined\"\n        }\n    },\n    \"calculate_expression\": {\n        \"description\": \"Always use this tool to provide reliable answers for expressions.\",\n        \"input_params\": {\n            \"expression\": \"The expression to be calculated\"\n        }\n    }\n}\n\ntools_available={\n    \"determine_properties\": determine_formula,\n    \"calculate_expression\": calculate_expression\n}\n</code></pre> <p>The <code>tools_description</code> and <code>tools_available</code> dictionaries contain the description of the tools and the actual functions that will be used to calculate the properties of the shapes. These dicts will be passed to the ReAct agent module as attributes.</p>","tags":["AI","LLMs","Agents"]},{"location":"blog/2024/12/20/understanding-and-building-react-agents/#react-agent-prompt","title":"ReAct Agent Prompt","text":"<pre><code>You are an AI assistant capable of reasoning and acting to answer complex questions. Your task is to use the tools provide and the steps already taken to the answer the given question.\n\n# You have access to the following tools:\n{tools_desc}\n\n# Steps so far:\n{steps}\n\n# To solve the problem, follow these steps:\n1. Analyse the question use the ONE tool which could help you the most to answer the question.\n2. Observe whether the response the of the tool is enough to answer the question.\n3. If not enough, use the another tools that can help you to answer the question.\n4. If one tool does not provide the required information, then use try using another tool.\n5. Repeat the process until you have enough information to answer the question.\n6. Once you have the final answer, respond ONLY with the answer.\n\n\nShow your reasoning and actions for each step. Use the format:\nThought: your thought process on the question\nAction: the tool to be used that can help you to answer the question and its input\n\nAnswer the following question:\n{question}\n\n{{\n    \"is_done\": true or false, whether the questions has been satisfactorily answered,\n    \"thought\": 'thought process',\n    \"action\": {{'tool_name': '', tool_input: {{}} }},\n    \"answer\": \"provide only this key in the response to respond with final answer\"\n}}\n</code></pre> <p>The ReAct agent prompt is a template that will be used to generate the traces for the ReAct agent. The prompt contains the tools description, the steps taken so far, and the question that the ReAct agent needs to answer. If the traces so far are enough to answer the question, then the <code>is_done</code> key will be set to <code>true</code> and the <code>answer</code> key will contain the final answer. If not, more step(s) will be added to the traces until the final answer is obtained.</p>","tags":["AI","LLMs","Agents"]},{"location":"blog/2024/12/20/understanding-and-building-react-agents/#react-agent-implementation","title":"ReAct Agent Implementation","text":"<pre><code>from openai import OpenAI\nfrom dotenv import load_dotenv\nimport json\n\nload_dotenv(\".env\")\n\n\nclass ReActAgent:\n    def __init__(self, tools_available, tools_desc: dict, model: str, verbose:bool = True):\n        self.tools_available = tools_available\n        self.tools_desc = tools_desc\n        self.model = model\n        self.client = OpenAI()\n        self.verbose = verbose\n\n    def complete(self, question, steps) -&gt; dict:\n        prompt = PROMPT_TEMPLATE.format(\n            tools_desc=self.tools_desc,\n            steps=steps,\n            question=question\n        )\n\n        response = self.client.chat.completions.create(\n            model=self.model,\n            response_format={ \"type\": \"json_object\" },\n            messages=[\n                {\"role\": \"system\", \"content\": \"You are a helpful asssistant who responds in JSON\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n        )\n\n        return json.loads(response.choices[0].message.content)\n\n    def query(self, question):\n        step_count = 0\n        steps = []\n        final_response = \"\"\n\n        while True:\n            response = self.complete(question, steps)\n            step_count += 1\n\n            if response[\"is_done\"]:\n                final_response = response[\"answer\"]\n                break\n\n            tool_name, tool_input = response[\"action\"][\"tool_name\"], response[\"action\"][\"tool_input\"]\n            tool_output = self.tools_available[tool_name](**tool_input)\n            step = f\"\"\"\n            Thought: {response[\"thought\"]}\n            Action: {tool_name}({tool_input})\n            Observation: {tool_output}\n            \"\"\"\n            print(step) if self.verbose else None\n            steps.append(step)\n\n\n        return {\n            \"content\": final_response,\n            \"steps\": steps\n        }\n</code></pre> <p>To instantiate the ReAct agent, the <code>tools_available</code> and <code>tools_description</code> dictionaries are passed as attributes. The <code>complete()</code> methods is used to populate the prompt and make the API call to the OpenAI chat endpoint. The user query is passed to the <code>query()</code> method which will keep calling the <code>complete()</code> method to generate the steps until the final answer is obtained. The <code>verbose</code> attribute can be set to <code>True</code> to print the steps taken by the ReAct agent.</p>","tags":["AI","LLMs","Agents"]},{"location":"blog/2024/12/20/understanding-and-building-react-agents/#running-the-react-agent","title":"Running the ReAct Agent","text":"<pre><code>questions = [\n    \"Calculate the area of rectangle with length 5 cm and breadth 12 cm\",\n    \"what is the area of circle with radius 10.35 inches\",\n    \"provide the area and perimeter of a square with sides 23m\",\n    \"what is the perimeter of a triangle with sides 10, 12 and 15 units\",\n    \"calculate the diagonal of a rectangle with length 10 cm and breadth 12 cm\",\n    \"what is the area of a parallelogram with base 12 cm, height 5 cm and angle 30 degrees\"\n]\n\nagent = ReActAgent(\n    tools_available=tools_available,\n    tools_desc=tools_description,\n    model=\"gpt-4o-mini\",\n    verbose=True\n)\n\nquestion = questions[2]\nprint(f\"Question: {question}\")\nresponse = agent.query(question)\nresponse[\"content\"]\n</code></pre> <p>Output:</p> <pre><code>Question: provide the area and perimeter of a square with sides 23m\n\n            Thought: To find the area and perimeter of a square with side length of 23m, I need to determine the formulas for both the area and perimeter. The shape is a square and the properties needed are area and perimeter.\n            Action: determine_properties({'shape': 'square', 'property': 'area'})\n            Observation: side ** 2\n\n\n            Thought: I have already determined that the formula for the area of a square is side ** 2. Now, I need to determine the formula for the perimeter of the square as well. The property needed is the perimeter.\n            Action: determine_properties({'shape': 'square', 'property': 'perimeter'})\n            Observation: 4 * side\n\n\n            Thought: I have determined the formulas for the area and perimeter of a square. The side length of the square is 23m. I need to calculate the area using the formula side ** 2 and the perimeter using the formula 4 * side. I'll start by calculating the area.\n            Action: calculate_expression({'expression': '23 ** 2'})\n            Observation: 529\n\n\n            Thought: I have already calculated the area of the square, which is 529 m\u00b2. Now I need to calculate the perimeter using the formula 4 * side.\n            Action: calculate_expression({'expression': '4 * 23'})\n            Observation: 92\n\nArea: 529 m\u00b2, Perimeter: 92 m\n</code></pre>","tags":["AI","LLMs","Agents"]},{"location":"blog/2025/01/01/a-comprehensive-guide-on-tf-idf/","title":"A Comprehensive Guide on TF-IDF","text":"<p>TF-IDF (Term Frequency-Inverse Document Frequency) is a popular technique in Natural Language Processing (NLP) for text analysis and information retrieval. It is used to evaluate the importance of a word in a document relative to a collection of documents (corpus). This guide provides an in-depth explanation of TF-IDF, its intuition, mathematical formulation, and implementation from scratch.</p>","tags":["NLP","RAG","Information Retrieval"]},{"location":"blog/2025/01/01/a-comprehensive-guide-on-tf-idf/#intuition-behind-tf-idf","title":"Intuition behind TF-IDF","text":"<p>Earlier search methods, and why they were not effective. What TF and IDF bring to the table.</p> <p>Before TF-IDF, the most common methods for text representation was Bag of Words (BOW). BOW represents text as a collection of words without considering the importance of certain words in context of the document or corpus. This method has some limitations:</p> <ol> <li> <p>All terms are treated equally: BOW assigns equal importance to all words in a document. This can be problematic because some words are more important than others.</p> </li> <li> <p>Doesn't account for word rarity: BOW doesn't consider the uniqueness of words across documents. Common words like \"the\", \"is\", \"and\" appear in many documents and are less helpful in distinguishing one document from another.</p> </li> </ol>","tags":["NLP","RAG","Information Retrieval"]},{"location":"blog/2025/01/01/a-comprehensive-guide-on-tf-idf/#how-tf-idf-overcomes-these-problems","title":"How TF IDF overcomes these problems","text":"<p>TF-IDF is a statistical measure that evaluates the importance of a word in a document relative to a collection of documents (corpus). It combines two metrics: Term Frequency (TF) and Inverse Document Frequency (IDF).</p> <p>Term Frequency (TF): Measures how often a terms appears in a document. Terms that appear more frequently in a document are likely important for that document.</p> <p>Inverse Document Frequency (IDF): Measures how unique or rare a word is across the entire corpus. If a word appears in many documents, it's less helpful in distinguishing one document from another (e.g., \"the\"). On the other hand, if a term appears in just a few documents, it's more distinctive.</p> <p>Combining these two metrics is useful for document search because it helps identify terms that are important to a document. For example, if you're searching for a document about the python programming language, you'd expect the terms \"python\" and \"programming\" to appear frequently. By calculating the TF-IDF score, we can identify terms that are important to a document while filtering out common terms like \"the\", \"is\", \"and\", etc. that appear in many documents.</p>","tags":["NLP","RAG","Information Retrieval"]},{"location":"blog/2025/01/01/a-comprehensive-guide-on-tf-idf/#tf-idf-explained","title":"TF IDF Explained","text":"<p>TF: This measures how often a word appears in a document. Words that appear more frequently in a document are likely important for that document.</p> <p>IDF: Inverse Document Frequency (IDF): This measures how unique or rare a word is across the entire corpus. If a word appears in many documents, it's less helpful in distinguishing one document from another (e.g., \"the\"). On the other hand, if a word appears in just a few documents, it's more distinctive.</p> <p>Combining TF IDF:</p> \\[ TF-IDF = TF * IDF \\] <p>High TF-IDF: The word is frequent in the document but rare in the corpus (important and unique).</p> <p>Low TF-IDF: The word is either common across the corpus or not frequent in the document (less important).</p>","tags":["NLP","RAG","Information Retrieval"]},{"location":"blog/2025/01/01/a-comprehensive-guide-on-tf-idf/#comparing-tf-idf-with-other-methods","title":"Comparing TF IDF with other methods","text":"","tags":["NLP","RAG","Information Retrieval"]},{"location":"blog/2025/01/01/a-comprehensive-guide-on-tf-idf/#pros","title":"Pros","text":"<ol> <li>Simple and easy to implement: TF-IDF is straightforward to implement, making it accessible for various applications in text analysis and NLP.</li> <li>Effective Keyword Extraction: It ranks words based on their frequency in a document relative to their frequency across a corpus, which enhances the identification of significant keywords.</li> <li>Works with large datasets: The more sophisticated implementations of TF-IDF can handle large datasets efficiently.</li> </ol>","tags":["NLP","RAG","Information Retrieval"]},{"location":"blog/2025/01/01/a-comprehensive-guide-on-tf-idf/#cons","title":"Cons","text":"<ol> <li>Biased towards long documents: TF-IDF can be biased towards longer documents, as they tend to have higher term frequencies.</li> <li>Does not have semantic understanding: TF-IDF does not consider the semantic meaning of words, which can lead to misinterpretation in context-rich environments.</li> <li>No Handling of Synonyms or Polysemy: While TF-IDF is effective, it may not perform as well in scenarios requiring deeper contextual understanding, such as sentiment analysis or nuanced language processing. It cannot resolve ambiguity in meaning (e.g., \"bank\" as a financial institution vs. a riverbank).</li> </ol>","tags":["NLP","RAG","Information Retrieval"]},{"location":"blog/2025/01/01/a-comprehensive-guide-on-tf-idf/#the-math-behind-tf-idf","title":"The Math Behind TF-IDF","text":"","tags":["NLP","RAG","Information Retrieval"]},{"location":"blog/2025/01/01/a-comprehensive-guide-on-tf-idf/#mathematical-formula","title":"Mathematical formula","text":"\\[ \\text{TF-IDF}(t, d, D) = \\text{TF}(t, d) \\times \\text{IDF}(t, D) \\] <p>Where:</p>","tags":["NLP","RAG","Information Retrieval"]},{"location":"blog/2025/01/01/a-comprehensive-guide-on-tf-idf/#term-frequency-tf","title":"Term Frequency (TF)","text":"\\[ \\text{TF}(t, d) = \\frac{f_{t, d}}{\\sum_{t' \\in d} f_{t', d}} \\] <ul> <li>\\(f_{t, d}\\): The frequency of term \\(t\\) in document \\(d\\).</li> <li>\\(\\sum_{t' \\in d} f_{t', d}\\): The total number of terms in document \\(d\\).</li> </ul>","tags":["NLP","RAG","Information Retrieval"]},{"location":"blog/2025/01/01/a-comprehensive-guide-on-tf-idf/#inverse-document-frequency-idf","title":"Inverse Document Frequency (IDF)","text":"\\[ \\text{IDF}(t, D) = \\log \\left( \\frac{|D|}{1 + |d \\in D : t \\in d|} \\right) \\] <ul> <li>\\(|D|\\): The total number of documents in the collection \\(D\\).</li> <li>\\(|d \\in D : t \\in d|\\): The number of documents in which the term \\(t\\) appears.</li> <li>\\(1\\): Added to avoid division by zero in case \\(t\\) does not appear in any document.</li> </ul>","tags":["NLP","RAG","Information Retrieval"]},{"location":"blog/2025/01/01/a-comprehensive-guide-on-tf-idf/#explanation","title":"Explanation","text":"<ul> <li> <p>Where \\(t\\) is the term: single word or token for which the TF-IDF score is being calculated.</p> </li> <li> <p>Where \\(d\\) is the document: A specific document from the corpus \\(D\\) where the term \\(t\\) is being considered.</p> </li> <li> <p>Where \\(D\\) is the corpus: The entire collection of documents.</p> </li> <li> <p>Where \\(f_{t, d}\\) is the term frequency: The raw count of term \\(t\\) in document \\(d\\).</p> </li> <li> <p>Where \\(\\log\\) is the logarithm function: Used to scale down the effect of IDF when a term appears in many documents.</p> </li> </ul>","tags":["NLP","RAG","Information Retrieval"]},{"location":"blog/2025/01/01/a-comprehensive-guide-on-tf-idf/#building-tf-idf-from-scratch","title":"Building TF-IDF from Scratch","text":"","tags":["NLP","RAG","Information Retrieval"]},{"location":"blog/2025/01/01/a-comprehensive-guide-on-tf-idf/#tf-idf-vectorizer-implementation","title":"TF-IDF Vectorizer Implementation","text":"<p>The <code>TfidfVectorizer</code> class is implemented in Python to calculate the TF-IDF score for a given corpus of documents. The class has three main methods:</p> <ol> <li><code>fit(corpus)</code>: This method calculates the vocabulary and document frequency for the given corpus.</li> <li><code>transform(corpus)</code>: This method calculates the TF-IDF score for each document in the corpus.</li> <li><code>fit_transform(corpus)</code>: This method combines the <code>fit</code> and <code>transform</code> methods to calculate the TF-IDF score in a single step.</li> </ol> <pre><code>import numpy as np\nimport pandas as pd\nimport math\n\nclass TfidfVectorizer:\n\n    def __init__(self):\n        self.vocabulary = {}\n        self.document_frequency = {}\n\n    def fit(self, corpus: list[str]): \n        # create vocabulary\n        for doc in corpus:\n            for word in set(doc.lower().split()):\n                if word not in self.vocabulary:\n                    self.vocabulary[word] = len(self.vocabulary)\n\n        # calculate the number of documents in which the terms in the vocabulary appears.\n        self.document_frequency = {term: 0 for term in self.vocabulary}\n        for doc in corpus:\n            unique_terms = set(doc.lower().split())\n            for word in unique_terms:\n                self.document_frequency[word] += 1\n\n        # calculate the inverse document frequency\n        self.inverse_document_frequency = {}\n        N = len(corpus)\n        for term, df in self.document_frequency.items():\n            self.inverse_document_frequency[term] = math.log(N/df+1)\n</code></pre> <p>The <code>fit</code> method does the following:</p> <ol> <li>Builds the vocabulary by reading through each document in the <code>corpus</code>. It breaks the document into words, converts them to lowercase, and takes only the unique words (using <code>set()</code>). It checks if each word is already in self.vocabulary. If not, it adds the word with a unique index (using the current length of the dictionary as the index).</li> <li><code>self.document_frequency</code> is initialized as a dictionary where each word (from the vocabulary) starts with a count of 0. For each document it extracts the unique words. Then, for each unique word in the document, increase its document frequency (DF) by 1.</li> <li>Calculates the Inverse Document Frequency (IDF) for each term in the vocabulary. It uses the formula: \\(\\text{IDF}(t, D) = \\log \\left( \\frac{|D|}{1 + |d \\in D : t \\in d|} \\right)\\).</li> </ol> <pre><code>    def transform(self, corpus: list[str]) -&gt; np.ndarray:\n        # initialize a matrix of zeros\n        tf_idf_matrix = np.zeros((len(corpus), len(self.vocabulary)))\n\n        # count the term frequency for each document\n        for i, doc in enumerate(corpus):\n            term_count = {}\n            for term in doc.lower().split():\n                term_count[term] = term_count.get(term, 0) + 1\n\n            # calculate the tf-idf score for each term in the document\n            for term, count in term_count.items():\n                if term in self.vocabulary:\n                    tf = count\n                    idf = self.inverse_document_frequency[term]\n                    tf_idf_matrix[i][self.vocabulary[term]] = tf * idf\n\n        return tf_idf_matrix \n\n    def fit_transform(self, corpus: list[str]) -&gt; np.ndarray:\n        self.fit(corpus)\n        result = self.transform(corpus)\n        return result\n</code></pre> <p>The <code>transform</code> method does the following:</p> <ol> <li>A 2D matrix of zeros is created. Rows = Number of documents in the corpus. Columns = Number of unique words in the vocabulary.</li> <li>Loop through each document in the corpus. For each document, count the frequency of each term, which is basically the Term Frequency (TF).</li> <li>Calculate the TF-IDF score for each term in the document. If the term is in the vocabulary, calculate the TF-IDF score by using the TF values calculated in the previous step and the IDF values calculated during the <code>fit</code> method.</li> </ol> <p>The <code>fit_transform</code> method combines the <code>fit</code> and <code>transform</code> methods to calculate the TF-IDF score in a single step.</p>","tags":["NLP","RAG","Information Retrieval"]},{"location":"blog/2025/01/01/a-comprehensive-guide-on-tf-idf/#example-usage","title":"Example Usage","text":"<pre><code>corpus = [\n    \"Apple Apple Banana\",\n    \"Banana Mango Banana\",\n    \"Cherry Cherry Cherry\",\n    \"Grapes Grapes Berries Grapes\",\n    \"Apple Banana Mango\",\n    \"Blueberries Strawberries Apple\",\n    \"Apple Banana Mango\",\n    \"Grapes Grapes Grapes\",\n    \"Blueberries Apple Strawberries\",\n    \"Apple Banana Apple\",\n    \"Cherry Cherry Mango Cherry\",\n    \"Blueberries Strawberries Cherry\",\n]\n\ndef format_matrix(vocab: dict, matrix: np.ndarray) -&gt; pd.DataFrame:\n    if len(vocab) == len(matrix[0]):\n        terms = list(vocab)\n        return pd.DataFrame(\n            data=matrix,\n            columns=terms\n        )\n    else:\n        raise ValueError(\"Vocabulary and Result matrix do not match\")\n\n\ntf_idf = TfidfVectorizer()\n\ntfidf_matrix = tf_idf.fit_transform(corpus)\n\nprint(f\"Vocab: {tf_idf.vocabulary}\")\nprint(f\"Document Frequency: {tf_idf.document_frequency}\")\nprint(f\"IDF: {tf_idf.inverse_document_frequency}\")\nprint(\"Result:\")\nformat_matrix(tf_idf.vocabulary, tfidf_matrix)\n</code></pre> <p>Output:</p> apple banana mango cherry grapes berries strawberries blueberries 0 2.197225 1.223775 0.000000 0.000000 0.00000 0.000000 0.000000 0.000000 1 0.000000 2.447551 1.386294 0.000000 0.00000 0.000000 0.000000 0.000000 2 0.000000 0.000000 0.000000 4.828314 0.00000 0.000000 0.000000 0.000000 3 0.000000 0.000000 0.000000 0.000000 5.83773 2.564949 0.000000 0.000000 4 1.098612 1.223775 1.386294 0.000000 0.00000 0.000000 0.000000 0.000000 5 1.098612 0.000000 0.000000 0.000000 0.00000 0.000000 1.609438 1.609438 6 1.098612 1.223775 1.386294 0.000000 0.00000 0.000000 0.000000 0.000000 7 0.000000 0.000000 0.000000 0.000000 5.83773 0.000000 0.000000 0.000000 8 1.098612 0.000000 0.000000 0.000000 0.00000 0.000000 1.609438 1.609438 9 2.197225 1.223775 0.000000 0.000000 0.00000 0.000000 0.000000 0.000000 10 0.000000 0.000000 1.386294 4.828314 0.00000 0.000000 0.000000 0.000000 11 0.000000 0.000000 0.000000 1.609438 0.00000 0.000000 1.609438 1.609438","tags":["NLP","RAG","Information Retrieval"]},{"location":"blog/2025/01/01/a-comprehensive-guide-on-tf-idf/#visualization-and-explanation","title":"Visualization and explanation","text":"<pre><code>import plotly.graph_objects as go\n\nx_values = [df for _, df in tf_idf.document_frequency.items()]\ny_values = [idf for _, idf in tf_idf.inverse_document_frequency.items()]\n\nfig = go.Figure()\n\nfig.add_trace(\n    go.Scatter(\n        x=x_values,\n        y=y_values,\n        mode=\"markers+lines\"\n    )\n)\n\nfig.update_layout(\n    title=\"DF vs IDF\",\n    xaxis_title=\"Document Frequency\",\n    yaxis_title=\"Inverse Document Frequency\"\n)\n\nfig.show()\n</code></pre> <p>The above chart shows how the IDF score changes as per the number of documents in which the term appears. As the number of documents increases, the IDF score decreases. This is because the term becomes less unique as it appears in more documents.</p>","tags":["NLP","RAG","Information Retrieval"]},{"location":"blog/2025/01/01/a-comprehensive-guide-on-tf-idf/#similarity-search-results","title":"Similarity search results","text":"<pre><code>from sklearn.metrics.pairwise import cosine_similarity\n\ndef retrieve_docs(query: str, corpus: list[str], docs_vector, tf_idf, top_k: int = 3):\n    query_vector = tf_idf.transform([query])\n    similarity_score = cosine_similarity(query_vector, result)\n    ranked_indices = similarity_score.argsort()[0][::-1][:top_k]\n    retrieved_docs = [{\"doc\": corpus[i], \"score\": round(float(similarity_score[0][i]), 3)} for i in ranked_indices]\n    return retrieved_docs\n\nqueries = [\n    \"Blueberries Strawberries\",\n    \"grapes\",\n    \"cherry\",\n    \"banana mango\"\n]\nquery = queries[3]\nprint(f\"Query: {query}\")\ndocs = retrieve_docs(query, corpus, result, tf_idf, top_k=5)\ndocs\n</code></pre> <p>Output:</p> <pre><code>Query: banana mango\n\n[{'doc': 'Banana Mango Banana', 'score': 0.945},\n {'doc': 'Apple Banana Mango', 'score': 0.86},\n {'doc': 'Apple Banana Mango', 'score': 0.86},\n {'doc': 'Apple Banana Apple', 'score': 0.322},\n {'doc': 'Apple Apple Banana', 'score': 0.322}]\n</code></pre> <p>The <code>retrieve_docs</code> function takes a query, corpus and returns the top-k most similar documents from the corpus based on the cosine similarity between the query and the documents. The function uses the <code>cosine_similarity</code> function from <code>sklearn</code> to calculate the similarity scores.</p>","tags":["NLP","RAG","Information Retrieval"]},{"location":"blog/2025/01/01/a-comprehensive-guide-on-tf-idf/#conclusion","title":"Conclusion","text":"<p>While TF-IDF has it's limitations, it remains a powerful tool for text analysis and information retrieval. It also layed the foundation for more advanced techniques like BM25 and word embeddings. Understanding the intuition, math, and implementation of TF-IDF is essential for anyone working with text data.</p>","tags":["NLP","RAG","Information Retrieval"]},{"location":"blog/archive/2025/","title":"2025","text":""},{"location":"blog/archive/2024/","title":"2024","text":""},{"location":"blog/category/information-retrieval/","title":"Information Retrieval","text":""},{"location":"blog/category/ai/","title":"AI","text":""}]}